{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07225c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN is a type of artificial Neural Network which is widely used for object/image recognition and classification.\n",
    "#Deep Learning recognizes objects in an image by using CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55e5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Dropout,Flatten,MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5eb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Loading and preprocessing the image data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "input_shape = (28,28,1)  # images are greyscale thats why input chaneel is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a469140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure that the values are float so that we can get the decimal points after devision\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "\n",
    "# print('Data type of x_train:',x_train.dtype)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# print('Data type of x_train after converting to float:',x_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c59802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training : (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the RGB codes by deviding it to the max RGB value\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "print('shape of training :',x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9427d1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of testing : (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('shape of testing :',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3bef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 28)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4732)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               946600    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 948890 (3.62 MB)\n",
      "Trainable params: 948890 (3.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# b. Defining the model‚Äôs architecture\n",
    "\n",
    "model = Sequential()  # used sequential as we have to add layers one after another\n",
    "model.add(Conv2D(28, kernel_size=(3,3),input_shape=input_shape))\n",
    "# kernel size - it is kernel size or filter size, it is an size of each convolutional layer, you can change size also\n",
    "# input shape is input size which we have declared above\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(200,activation='relu'))  # Hidden Layer\n",
    "model.add(Dropout(0.3))                  # Will drop some random neurons from hidden layer, 30%neurons will be removed\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fef28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 70s 36ms/step - loss: 0.2018 - accuracy: 0.9387\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0833 - accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22a01f50c10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c. Training the model\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "loss = 'sparse_categorical_crossentropy',\n",
    "metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b54a70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0654 - accuracy: 0.9786\n",
      "loss=0.065\n",
      "Accuracy=0.979\n"
     ]
    }
   ],
   "source": [
    "# d. Estimating the model‚Äôs performance\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('loss=%.3f' %test_loss)\n",
    "print('Accuracy=%.3f' %test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8149f45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN8klEQVR4nO3df6jVdZ7H8ddrbfojxzI39iZOrWOEUdE6i9nSyjYRTj8o7FYMIzQ0JDl/JDSwyIb7xxSLIVu6rBSDDtXYMus0UJHFMNVm5S6BdDMrs21qoxjlphtmmv1a9b1/3K9xp+75nOs53/PD+34+4HDO+b7P93zffPHl99f53o8jQgAmvj/rdQMAuoOwA0kQdiAJwg4kQdiBJE7o5sJsc+of6LCI8FjT29qy277C9lu237F9ezvfBaCz3Op1dtuTJP1B0gJJOyW9JGlRROwozMOWHeiwTmzZ50l6JyLejYgvJf1G0sI2vg9AB7UT9hmS/jjq/c5q2p+wvcT2kO2hNpYFoE0dP0EXEeskrZPYjQd6qZ0t+y5JZ4x6/51qGoA+1E7YX5J0tu3v2j5R0o8kbaynLQB1a3k3PiIO2V4q6SlJkyQ9EBFv1NYZgFq1fOmtpYVxzA50XEd+VAPg+EHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEi0P2Yzjw6RJk4r1U045paPLX7p0acPaSSedVJx39uzZxfqtt95arN9zzz0Na4sWLSrO+/nnnxfrK1euLNbvvPPOYr0X2gq77fckHZB0WNKhiJhbR1MA6lfHlv3SiPiwhu8B0EEcswNJtBv2kPS07ZdtLxnrA7aX2B6yPdTmsgC0od3d+PkRscv2X0h6xvZ/R8Tm0R+IiHWS1kmS7WhzeQBa1NaWPSJ2Vc97JD0maV4dTQGoX8thtz3Z9pSjryX9QNL2uhoDUK92duMHJD1m++j3/HtE/L6WriaYM888s1g/8cQTi/WLL764WJ8/f37D2tSpU4vzXn/99cV6L+3cubNYX7NmTbE+ODjYsHbgwIHivK+++mqx/sILLxTr/ajlsEfEu5L+qsZeAHQQl96AJAg7kARhB5Ig7EAShB1IwhHd+1HbRP0F3Zw5c4r1TZs2Feudvs20Xx05cqRYv/nmm4v1Tz75pOVlDw8PF+sfffRRsf7WW2+1vOxOiwiPNZ0tO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXX2GkybNq1Y37JlS7E+a9asOtupVbPe9+3bV6xfeumlDWtffvllcd6svz9oF9fZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJhmyuwd69e4v1ZcuWFetXX311sf7KK68U683+pHLJtm3bivUFCxYU6wcPHizWzzvvvIa12267rTgv6sWWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4H72PnDyyScX682GF167dm3D2uLFi4vz3njjjcX6hg0binX0n5bvZ7f9gO09trePmjbN9jO2366eT62zWQD1G89u/K8kXfG1abdLejYizpb0bPUeQB9rGvaI2Czp678HXShpffV6vaRr620LQN1a/W38QEQcHSzrA0kDjT5oe4mkJS0uB0BN2r4RJiKidOItItZJWidxgg7opVYvve22PV2Squc99bUEoBNaDftGSTdVr2+S9Hg97QDolKa78bY3SPq+pNNs75T0c0krJf3W9mJJ70v6YSebnOj279/f1vwff/xxy/PecsstxfrDDz9crDcbYx39o2nYI2JRg9JlNfcCoIP4uSyQBGEHkiDsQBKEHUiCsANJcIvrBDB58uSGtSeeeKI47yWXXFKsX3nllcX6008/Xayj+xiyGUiOsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dr7BHfWWWcV61u3bi3W9+3bV6w/99xzxfrQ0FDD2n333Vect5v/NicSrrMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJcZ09ucHCwWH/wwQeL9SlTprS87OXLlxfrDz30ULE+PDxcrGfFdXYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSILr7Cg6//zzi/XVq1cX65dd1vpgv2vXri3WV6xYUazv2rWr5WUfz1q+zm77Adt7bG8fNe0O27tsb6seV9XZLID6jWc3/leSrhhj+r9ExJzq8bt62wJQt6Zhj4jNkvZ2oRcAHdTOCbqltl+rdvNPbfQh20tsD9lu/MfIAHRcq2H/haSzJM2RNCxpVaMPRsS6iJgbEXNbXBaAGrQU9ojYHRGHI+KIpF9KmldvWwDq1lLYbU8f9XZQ0vZGnwXQH5peZ7e9QdL3JZ0mabekn1fv50gKSe9J+mlENL25mOvsE8/UqVOL9WuuuaZhrdm98vaYl4u/smnTpmJ9wYIFxfpE1eg6+wnjmHHRGJPvb7sjAF3Fz2WBJAg7kARhB5Ig7EAShB1Igltc0TNffPFFsX7CCeWLRYcOHSrWL7/88oa1559/vjjv8Yw/JQ0kR9iBJAg7kARhB5Ig7EAShB1IgrADSTS96w25XXDBBcX6DTfcUKxfeOGFDWvNrqM3s2PHjmJ98+bNbX3/RMOWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dr7BDd79uxifenSpcX6ddddV6yffvrpx9zTeB0+fLhYHx4u//XyI0eO1NnOcY8tO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXX240Cza9mLFo010O6IZtfRZ86c2UpLtRgaGirWV6xYUaxv3LixznYmvKZbdttn2H7O9g7bb9i+rZo+zfYztt+unk/tfLsAWjWe3fhDkv4+Is6V9DeSbrV9rqTbJT0bEWdLerZ6D6BPNQ17RAxHxNbq9QFJb0qaIWmhpPXVx9ZLurZDPQKowTEds9ueKel7krZIGoiIoz9O/kDSQIN5lkha0kaPAGow7rPxtr8t6RFJP4uI/aNrMTI65JiDNkbEuoiYGxFz2+oUQFvGFXbb39JI0H8dEY9Wk3fbnl7Vp0va05kWAdSh6W68bUu6X9KbEbF6VGmjpJskrayeH+9IhxPAwMCYRzhfOffcc4v1e++9t1g/55xzjrmnumzZsqVYv/vuuxvWHn+8/E+GW1TrNZ5j9r+V9GNJr9veVk1brpGQ/9b2YknvS/phRzoEUIumYY+I/5I05uDuki6rtx0AncLPZYEkCDuQBGEHkiDsQBKEHUiCW1zHadq0aQ1ra9euLc47Z86cYn3WrFmttFSLF198sVhftWpVsf7UU08V65999tkx94TOYMsOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mkuc5+0UUXFevLli0r1ufNm9ewNmPGjJZ6qsunn37asLZmzZrivHfddVexfvDgwZZ6Qv9hyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSaS5zj44ONhWvR07duwo1p988sli/dChQ8V66Z7zffv2FedFHmzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR0T5A/YZkh6SNCApJK2LiH+1fYekWyT9b/XR5RHxuybfVV4YgLZFxJijLo8n7NMlTY+IrbanSHpZ0rUaGY/9k4i4Z7xNEHag8xqFfTzjsw9LGq5eH7D9pqTe/mkWAMfsmI7Zbc+U9D1JW6pJS22/ZvsB26c2mGeJ7SHbQ+21CqAdTXfjv/qg/W1JL0haERGP2h6Q9KFGjuP/SSO7+jc3+Q5244EOa/mYXZJsf0vSk5KeiojVY9RnSnoyIs5v8j2EHeiwRmFvuhtv25Lul/Tm6KBXJ+6OGpS0vd0mAXTOeM7Gz5f0n5Jel3Skmrxc0iJJczSyG/+epJ9WJ/NK38WWHeiwtnbj60LYgc5reTcewMRA2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLbQzZ/KOn9Ue9Pq6b1o37trV/7kuitVXX29peNCl29n/0bC7eHImJuzxoo6Nfe+rUvid5a1a3e2I0HkiDsQBK9Dvu6Hi+/pF9769e+JHprVVd66+kxO4Du6fWWHUCXEHYgiZ6E3fYVtt+y/Y7t23vRQyO237P9uu1tvR6frhpDb4/t7aOmTbP9jO23q+cxx9jrUW932N5Vrbtttq/qUW9n2H7O9g7bb9i+rZre03VX6Ksr663rx+y2J0n6g6QFknZKeknSoojY0dVGGrD9nqS5EdHzH2DY/jtJn0h66OjQWrb/WdLeiFhZ/Ud5akT8Q5/0doeOcRjvDvXWaJjxn6iH667O4c9b0Yst+zxJ70TEuxHxpaTfSFrYgz76XkRslrT3a5MXSlpfvV6vkX8sXdegt74QEcMRsbV6fUDS0WHGe7ruCn11RS/CPkPSH0e936n+Gu89JD1t+2XbS3rdzBgGRg2z9YGkgV42M4amw3h309eGGe+bddfK8Oft4gTdN82PiL+WdKWkW6vd1b4UI8dg/XTt9BeSztLIGIDDklb1splqmPFHJP0sIvaPrvVy3Y3RV1fWWy/CvkvSGaPef6ea1hciYlf1vEfSYxo57Ognu4+OoFs97+lxP1+JiN0RcTgijkj6pXq47qphxh+R9OuIeLSa3PN1N1Zf3VpvvQj7S5LOtv1d2ydK+pGkjT3o4xtsT65OnMj2ZEk/UP8NRb1R0k3V65skPd7DXv5Evwzj3WiYcfV43fV8+POI6PpD0lUaOSP/P5L+sRc9NOhrlqRXq8cbve5N0gaN7Nb9n0bObSyW9OeSnpX0tqT/kDStj3r7N40M7f2aRoI1vUe9zdfILvprkrZVj6t6ve4KfXVlvfFzWSAJTtABSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBL/DyJ7caZa7LphAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing image at position[] from dataset\n",
    "\n",
    "image = x_train[0]\n",
    "plt.imshow(np.squeeze(image),cmap='gray')  # it will remove arrays of single diamensional\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81916772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 216ms/step\n",
      "predicted class: 5\n"
     ]
    }
   ],
   "source": [
    "# predicting the class of image\n",
    "\n",
    "image = image.reshape(1,image.shape[0],image.shape[1],image.shape[2])\n",
    "predict_model = model.predict([image])\n",
    "print('predicted class: {}'.format(np.argmax(predict_model)))  # it displays max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Perfect ‚Äî your file implements **image classification using a CNN (Convolutional Neural Network)** on the **MNIST dataset** (handwritten digits 0‚Äì9). Below is a **complete theoretical explanation** of every concept in your practical, followed by **expected viva questions and their ideal answers** ‚Äî exactly as a university external (like an SPPU chief officer) would ask.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **Theory: CNN-based Image Classification Model**\n",
    "\n",
    "### 1. **Aim**\n",
    "\n",
    "To implement an image classification model using the **Convolutional Neural Network (CNN)** deep learning architecture.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Introduction**\n",
    "\n",
    "A **Convolutional Neural Network (CNN)** is a specialized deep learning architecture mainly used for **image recognition, classification, and object detection** tasks.\n",
    "It automatically learns **spatial hierarchies of features** (edges ‚Üí textures ‚Üí shapes ‚Üí objects) from images.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Dataset Used ‚Äî MNIST**\n",
    "\n",
    "* **MNIST** stands for *Modified National Institute of Standards and Technology*.\n",
    "* It contains **70,000 grayscale images** of handwritten digits (0‚Äì9).\n",
    "\n",
    "  * 60,000 images for **training**\n",
    "  * 10,000 images for **testing**\n",
    "* Each image is **28 √ó 28 pixels** and **single-channel (grayscale)**.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Steps Involved**\n",
    "\n",
    "#### a. **Importing Libraries**\n",
    "\n",
    "* **TensorFlow / Keras** ‚Üí building and training deep learning models.\n",
    "* **Matplotlib** ‚Üí for visualization.\n",
    "* **NumPy** ‚Üí for numerical operations.\n",
    "\n",
    "#### b. **Data Loading and Preprocessing**\n",
    "\n",
    "```python\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "```\n",
    "\n",
    "* Loads data in two sets: training and testing.\n",
    "* Reshape to `(28, 28, 1)` to match CNN input shape.\n",
    "* Normalize pixel values:\n",
    "\n",
    "  ```python\n",
    "  x_train = x_train / 255\n",
    "  ```\n",
    "\n",
    "  This scales data to range [0, 1] ‚Äî helps faster convergence.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **CNN Architecture**\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "```\n",
    "\n",
    "#### ‚û§ **Layer-wise Explanation:**\n",
    "\n",
    "| Layer              | Purpose                                                               | Key Concept                                                                           |\n",
    "| ------------------ | --------------------------------------------------------------------- | ------------------------------------------------------------------------------------- |\n",
    "| **Conv2D**         | Extracts local features from images using filters (kernels).          | The filter slides over the image performing convolution to detect edges, curves, etc. |\n",
    "| **MaxPooling2D**   | Reduces spatial dimension ‚Üí reduces computation & avoids overfitting. | Takes the max value from a region (e.g., 2√ó2).                                        |\n",
    "| **Flatten**        | Converts 2D feature maps into 1D vector.                              | Required for feeding data into Dense layers.                                          |\n",
    "| **Dense (Hidden)** | Fully connected layer for learning complex relationships.             | Uses ReLU activation for non-linearity.                                               |\n",
    "| **Dropout**        | Randomly drops neurons during training to prevent overfitting.        | Here, 30% of neurons are dropped.                                                     |\n",
    "| **Dense (Output)** | Outputs probability for each class (0‚Äì9).                             | Softmax converts scores to probability distribution.                                  |\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Compilation**\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "```\n",
    "\n",
    "* **Optimizer (Adam):** Adaptive optimizer that adjusts learning rate.\n",
    "* **Loss Function:**\n",
    "  `sparse_categorical_crossentropy` ‚Äì used when labels are integers (not one-hot encoded).\n",
    "* **Metric:** Accuracy ‚Äì measures performance on training/test data.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Training**\n",
    "\n",
    "```python\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "```\n",
    "\n",
    "* **Epoch:** One complete pass of the dataset through the model.\n",
    "* **Batch size (default = 32):** Number of samples processed before updating weights.\n",
    "* During training, the model adjusts weights using **backpropagation**.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Evaluation**\n",
    "\n",
    "```python\n",
    "model.evaluate(x_test, y_test)\n",
    "```\n",
    "\n",
    "* Evaluates model on unseen test data to check generalization.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Prediction**\n",
    "\n",
    "```python\n",
    "predictions = model.predict(x_test)\n",
    "```\n",
    "\n",
    "* Gives probability of each digit (0‚Äì9) for every test image.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. **Visualization (Optional)**\n",
    "\n",
    "* Use `matplotlib` to show sample images and their predicted labels.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò **Key Concepts You Must Understand**\n",
    "\n",
    "| Concept                                 | Explanation                                                                                    |\n",
    "| --------------------------------------- | ---------------------------------------------------------------------------------------------- |\n",
    "| **Convolution**                         | Operation of applying filters to extract features like edges, corners, etc.                    |\n",
    "| **Feature Map**                         | The output of a convolution operation showing detected features.                               |\n",
    "| **Pooling**                             | Downsampling method to reduce feature map size.                                                |\n",
    "| **Activation Function (ReLU, Softmax)** | Adds non-linearity; ReLU removes negative values; Softmax converts outputs into probabilities. |\n",
    "| **Dropout**                             | Technique to prevent overfitting by ignoring random neurons.                                   |\n",
    "| **Overfitting**                         | Model performs well on training but poorly on new data.                                        |\n",
    "| **Epoch**                               | One complete iteration over the dataset.                                                       |\n",
    "| **Optimizer (Adam)**                    | Efficient algorithm for updating weights.                                                      |\n",
    "| **Loss Function**                       | Measures difference between predicted and actual output.                                       |\n",
    "\n",
    "---\n",
    "\n",
    "## üó£Ô∏è **Viva / Oral Questions with Answers**\n",
    "\n",
    "### üîπ **Basic Level**\n",
    "\n",
    "1. **Q:** What is CNN?\n",
    "   **A:** CNN is a deep learning model designed for image-related tasks. It automatically extracts and learns features from images using convolution and pooling layers.\n",
    "\n",
    "2. **Q:** Why do we normalize images?\n",
    "   **A:** To scale pixel values (0‚Äì255) to (0‚Äì1), which helps the model train faster and improves numerical stability.\n",
    "\n",
    "3. **Q:** Why use ReLU activation?\n",
    "   **A:** ReLU introduces non-linearity and prevents vanishing gradient problems.\n",
    "\n",
    "4. **Q:** What does Softmax do?\n",
    "   **A:** Converts raw outputs into probabilities that sum to 1 ‚Äî used for multiclass classification.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Intermediate Level**\n",
    "\n",
    "5. **Q:** What is the difference between Dense and Convolutional layers?\n",
    "   **A:** Dense layers connect every neuron to every other neuron, while Convolutional layers use small filters to focus on spatial patterns.\n",
    "\n",
    "6. **Q:** Why do we use Dropout?\n",
    "   **A:** To reduce overfitting by randomly turning off neurons during training.\n",
    "\n",
    "7. **Q:** What optimizer did you use and why?\n",
    "   **A:** Adam optimizer ‚Äî combines the advantages of AdaGrad and RMSProp, adapting learning rates automatically.\n",
    "\n",
    "8. **Q:** What loss function is used for MNIST?\n",
    "   **A:** Sparse categorical cross-entropy ‚Äî suitable for multi-class problems with integer labels.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Advanced Level (Chief Examiner Style)**\n",
    "\n",
    "9. **Q:** How does a CNN differ from a simple ANN?\n",
    "   **A:** CNNs handle image data with spatial hierarchies using convolution and pooling, while ANNs require flattened inputs and cannot capture local spatial relationships effectively.\n",
    "\n",
    "10. **Q:** What happens during backpropagation in CNNs?\n",
    "    **A:** The model updates filter weights and biases using gradient descent to minimize loss based on the error between predicted and actual outputs.\n",
    "\n",
    "11. **Q:** Why do we use Flatten before Dense?\n",
    "    **A:** Because Dense layers expect 1D input, while feature maps from convolution layers are 2D.\n",
    "\n",
    "12. **Q:** How many trainable parameters are there in your model?\n",
    "    **A:** You can check with `model.summary()`. It shows total trainable parameters ‚Äî derived from weights and biases of each layer.\n",
    "\n",
    "13. **Q:** How can you improve accuracy?\n",
    "    **A:** By increasing epochs, adding more convolution layers, using data augmentation, or tuning hyperparameters.\n",
    "\n",
    "---\n",
    "\n",
    "## üèÅ **Conclusion**\n",
    "\n",
    "The CNN model successfully learns to classify handwritten digits with high accuracy.\n",
    "It demonstrates how deep learning automates feature extraction and classification in image processing tasks.\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
